# Changes made on 2025-11-02 (migration / viewer / worker fixes)

This file documents the edits made today to support moving PDFs into Supabase Storage, hardening the Cloudflare Worker (`cors-proxy`) and improving the viewer integration. The focus here is to describe the concrete methods added to the worker and the generator scripts (shell + Python) used to produce `data/*.json` and templates.

NOTE: This document intentionally excludes the `prev/next` navigation changes (they were implemented separately).

---

## Worker: key helper methods and handlers

The Cloudflare Worker code (`cors-proxy/src/api/rw-supabase.js` and router wiring in `src/index.js`) was updated with several small helpers and a new streaming/HEAD approach. The main responsibilities are: resolve or produce an accessible URL for a file object in Supabase Storage; perform server-side authenticated HEAD/GET requests when appropriate; and safely proxy bytes (including Range requests) to the client while ensuring CORS headers are present.

The important methods and what they do:

- getSignedUrl(env, bucket, storageKey)
  - Attempts to call the Supabase Storage sign endpoint for the given object.
  - Defensive about request/response variations: some Supabase sign endpoints accept `expiresIn`, others `expires_in`, and responses vary (`signedURL`, `signedUrl`, `url`, or `path` + `token`).
  - Returns the raw sign endpoint response body when available so the caller can try to extract a usable URL.
  - Logs are masked/minimized to avoid printing raw tokens.

- resolveSignedUrl(body, env)
  - Accepts the sign endpoint response body and tries to extract a usable URL via several heuristics:
    - look for `signedURL`, `signedUrl`, `url` fields,
    - if `path` + `token` present, append `token` as query param to `path`,
    - if only a path is present and the environment provides a canonical base, construct a full URL.
  - Returns either a URL string or `null` if none of the heuristics match.

- serviceRoleFetchObject(env, bucket, storageKey, options)
  - Uses the Supabase service-role key (kept in worker secrets) to perform a server-side fetch against the Supabase Storage REST endpoint: `${SUPABASE_URL}/storage/v1/object/${bucket}/${storageKey}`.
  - Supports HEAD and GET. For GET, forwards `Range` header from the incoming client request if present to support partial content streaming needed by PDF viewers.
  - Returns the fetch Response object directly so the router can proxy status, headers and body.
  - This method avoids creating signed URLs and instead performs the fetch with a server-side secret — useful where signing endpoints are inconsistent.

- resourceStreamFromSupabase(request, env, ctx)
  - Top-level handler wired to `/api/resources/:id/stream`.
  - Fetches metadata for the resource (from `fileStore` table via REST or Postgres) to discover the `storage_key` and `bucket`.
  - Prefer the service-role fetch method when the service key is available: call `serviceRoleFetchObject(...)` and stream back headers/body to the client.
  - If service-role isn't available, falls back to `getSignedUrl()` + `resolveSignedUrl()` flow. Defensive parsing prevents the worker from crashing on empty/non-JSON responses.
  - Ensures CORS headers are attached to proxied responses and masks sensitive values in logs.

- HEAD handler
  - A minimal route that returns an HTTP HEAD response for a resource. If service-role fetch is possible, performs a HEAD to the storage object to determine existence without transferring bytes. If not, the handler attempts to use sign/metadata heuristics safely.

Notes about behavior and security
- All proxied GETs forward the client's Range header when present, letting the underlying storage respond with 206 Partial Content as appropriate.
- The service-role key must be kept secret and stored in the Worker environment (do not embed in client code). The worker uses it server-side only.
- Logging was made defensive and tokens/URLs are masked or trimmed where possible to avoid secret leakage.


## Generator scripts (shell + Python)

Two utility scripts were added/used to produce the `data/<subject>.json` and the `templates/<subject>.html` artifacts used by the site and by the viewer/navigation logic.

### tools/gen-wd-json.sh (shell)

Purpose
- Query the Supabase `fileStore` REST endpoint (service-role auth) and produce one `data/<subject>.json` file per subject. Each JSON has a `units` array containing `groups` and `files` entries in the expected shape.

Important behavior & methods
- Environment variables required:
  - `SUPABASE_URL` — base URL for the Supabase project.
  - `SUPABASE_SERVICE_ROLE_KEY` — service role key used for authenticated REST calls.
  - Optional: `API_PROXY_BASE` — base URL used to build `url` field for each file (defaults to a dev worker or localhost depending on context).

- PROXY_BASE selection logic:
  - If `API_PROXY_BASE` is set, it is used.
  - Otherwise, if the environment indicates production Pages or similar (presence of `PAGES_URL` or `CF_PAGES` or `SUPABASE_URL` contains `pages.dev`), the script uses a production proxy base (example: `https://cors-proxy.devpages.workers.dev`).
  - Otherwise defaults to `http://localhost:8787` for local dev.

- Data query and transform:
  - The script builds an API URL against `/rest/v1/fileStore` with `select` to get fields: `id,filename,resource_type,unit,storage_key,subject,link_title`.
  - It calls `curl` using the service-role key in both `Authorization` and `apikey` headers.
  - The JSON response is piped into `jq` which groups rows by `subject`, then by `unit`, then by `resource_type`, assembling a nested `{ units: [ { unit, groups: [{type, files:[...]}, ...] }, ...] }` object for each subject.
  - For each file, the script constructs a `url` using the chosen proxy base plus the path `/api/resources/<id>/stream` (this is how the viewer later loads the resource via the worker).

- Output
  - Files are written into `data/<subject>.json`.
  - If no rows are returned, the script still ensures `data/misc.json` exists with an empty `units` array.

Why this is useful
- These JSON files are canonical, generator-produced indexes of the site's stored PDF resources. They are consumed by the HTML generator and the viewer navigation code to restore structured navigation without scanning the repo or relying on heuristics.

### tools/gen-web-design-html.py (Python)

Purpose
- Read all `data/*.json` files and write `templates/<subject>.html` (simple details-based HTML fragments) used by the site to render subject navigation and links.

Key functions and behavior
- esc(s)
  - Small HTML-escaping helper to escape `&`, `<`, and `>` in title/text values to avoid markup injection when writing templates.

- extract_leading_number(filename)
  - Attempts to extract a leading numeric index from a filename (used for ordering). If a leading number is present, returns it as an integer; if not, tries to find any numeric substring; otherwise returns a very large number so that unnumbered files sort later.

- Template generation
  - For each `data/<subject>.json`, the script builds a small `<details>` block containing units → groups → files. Each file becomes a link to `/pdf-viewer/?file=<resource_url>&title=<link_text>` where `resource_url` is taken from the data JSON (the proxy stream URL produced by the shell script).
  - Files are sorted using `extract_leading_number` and then filename to keep a natural ordering.
  - The generated templates are written to `templates/<subject>.html` and include a comment line showing which source JSON they were generated from.

Why this is useful
- Separates the data (structured JSON) from HTML templates. The generated templates are consumable by the Zola site and provide stable viewer links pointing at the proxy stream.
